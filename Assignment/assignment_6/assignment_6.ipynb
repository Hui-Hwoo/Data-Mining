{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_roc_curve(labels, scores):\n",
    "    # sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(scores, kind=\"mergesort\")[::-1]\n",
    "    scores = scores[desc_score_indices]\n",
    "    labels = labels[desc_score_indices]\n",
    "\n",
    "    # scores typically has many tied values. Here we extract\n",
    "    # the indices associated with the distinct values. We also\n",
    "    # concatenate a value for the end of the curve.\n",
    "    distinct_value_indices = np.where(np.diff(scores))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, labels.size - 1]\n",
    "\n",
    "    # accumulate the true positives with decreasing threshold\n",
    "    tps = np.cumsum(labels, dtype=np.float64)[threshold_idxs]\n",
    "    fps = 1 + threshold_idxs - tps\n",
    "    thresholds = scores[threshold_idxs]\n",
    "\n",
    "    optimal_idxs = np.where(\n",
    "        np.r_[True, np.logical_or(np.diff(fps, 2), np.diff(tps, 2)), True]\n",
    "    )[0]\n",
    "    fps = fps[optimal_idxs]\n",
    "    tps = tps[optimal_idxs]\n",
    "    thresholds = thresholds[optimal_idxs]\n",
    "\n",
    "    # Add an extra threshold position\n",
    "    # to make sure that the curve starts at (0, 0)\n",
    "    tps = np.r_[0, tps]\n",
    "    fps = np.r_[0, fps]\n",
    "\n",
    "    fpr = fps / fps[-1]\n",
    "    tpr = tps / tps[-1]\n",
    "    thresholds = np.r_[np.inf, thresholds]\n",
    "\n",
    "    return fpr, tpr, thresholds\n",
    "\n",
    "\n",
    "\n",
    "def roc_range(scores, labels, maxfpr, minfpr = 0):\n",
    "  \"\"\"\n",
    "    Inputs:\n",
    "    scores - predictions from any given classifier\n",
    "    labels - the true label (either 0, 1) of the data\n",
    "    maxfpr - the maximum false positive rate (FPR)\n",
    "    minfpr (optional, default = 0) - the minimum false positive rate (FPR)\n",
    "\n",
    "    Outputs:\n",
    "    fpr_in_range - list of FPR values from minpfa to maxpfa\n",
    "    tpr_in_range - list of true positive rate (TPR) values from minfpr to maxfpr\n",
    "    auc_in_range - single value of area under curve from minpfa to maxpfa\n",
    "  \"\"\"\n",
    "  fpr, tpr, _ = my_roc_curve(labels, scores)\n",
    "  \n",
    "  auc_in_range = 0\n",
    "  fpr_in_range = []\n",
    "  tpr_in_range = []\n",
    "  for i in range(len(fpr)):\n",
    "    if fpr[i] >= minfpr and fpr[i] <= maxfpr:\n",
    "      fpr_in_range.append(fpr[i])\n",
    "      tpr_in_range.append(tpr[i])\n",
    "      auc_in_range += (fpr[i] - fpr[i-1]) * tpr[i]\n",
    "\n",
    "  return fpr_in_range, tpr_in_range, auc_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: FPR ∈ [0, 1.0], AUC = 0.824412\n",
      "Range: FPR ∈ [0, 0.4], AUC = 0.2522660000000001\n",
      "Range: FPR ∈ [0, 0.75], AUC = 0.574101\n",
      "Range: FPR ∈ [0.25, 0.75], AUC = 0.44496199999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Usage\n",
    "TEST_MODE = False # Change to True to test on small dataset\n",
    "data = np.load(\"assignment6.npz\")\n",
    "\n",
    "scores_small = data['scores_small']\n",
    "scores_large = data['scores_large']\n",
    "labels_small = data['labels_small']\n",
    "labels_large = data['labels_large']\n",
    "\n",
    "if TEST_MODE:\n",
    "  scores = scores_small\n",
    "  labels = labels_small\n",
    "else:\n",
    "  scores = scores_large\n",
    "  labels = labels_large\n",
    "\n",
    "\"\"\"\n",
    "a) PF A ∈ [0, 1.0], the full range of thresholds\n",
    "b) PF A ∈ [0, 0.4]\n",
    "c) PF A ∈ [0, 0.75]\n",
    "d) PF A ∈ [0.25, 0.75]\n",
    "\"\"\"\n",
    "\n",
    "ranges = [[0, 1.0], [0, 0.4], [0, 0.75], [0.25, 0.75]]\n",
    "for idx, r in enumerate(ranges):\n",
    "  fpr, tpr, auc = roc_range(scores, labels, r[1], r[0])\n",
    "  plt.plot(fpr, tpr, label='FPR ∈ [0.25, 0.75] (AUC = %0.2f)' % auc)\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('ROC Curve')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.savefig(f\"roc_curve_{chr(ord('a') + idx)}.png\")\n",
    "  plt.clf()\n",
    "  print(f\"Range: FPR ∈ [{r[0]}, {r[1]}], AUC = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1.1259688898342692, Precision: 0.9096209912536443\n",
      "Accuracy: 0.6405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get precision for the full range of thresholds\n",
    "# What thresholds provide a precision of 0.9?\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, roc_curve\n",
    "\n",
    "def precision_range(scores, labels):\n",
    "  _, _, thresholds = roc_curve(labels, scores)\n",
    "  precision = []\n",
    "  accuracy = []\n",
    "\n",
    "  for i in range(len(thresholds)):\n",
    "    y_pred = scores > thresholds[i]\n",
    "    precision.append(precision_score(labels, y_pred, zero_division=0))\n",
    "    accuracy.append(accuracy_score(labels, y_pred))\n",
    "\n",
    "  return precision, accuracy, thresholds\n",
    "\n",
    "# Sample Usage\n",
    "precision, accuracy, thresholds = precision_range(scores_large, labels_large)\n",
    "\n",
    "# Find the threshold that provides a precision of 0.9\n",
    "for i in range(len(precision)):\n",
    "  if 0.91 > precision[i] >= 0.9:\n",
    "    print(f\"Threshold: {thresholds[i]}, Precision: {precision[i]}\")\n",
    "    print(f\"Accuracy: {accuracy[i]}\")\n",
    "    break\n",
    "\n",
    "plt.plot(thresholds, precision)\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision vs Thresholds')\n",
    "plt.savefig(\"precision_thresholds.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(thresholds, accuracy)\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Thresholds')\n",
    "plt.savefig(\"accuracy_thresholds.png\")\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
